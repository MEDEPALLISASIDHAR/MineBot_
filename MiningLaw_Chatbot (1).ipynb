{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hRR7mDAB72t7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your TXT file is in your Colab Notebooks folder\n",
        "file_path = '/content/CHatBotDataset.txt'  # Replace with the correct path\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "  data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1E__U7n8vQ6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Remove newline characters\n",
        "cleaned_data = re.sub(r'\\n', '', data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CAKLj9J8vut"
      },
      "outputs": [],
      "source": [
        "sentences = cleaned_data.split(\". \")  # Split by full stop followed by space\n",
        "sentences = [sentence for sentence in sentences if sentence.strip()]  # Remove empty elements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF_F_dvH8yNY"
      },
      "outputs": [],
      "source": [
        "sentences = [sentence.lower() for sentence in sentences]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ZG6WMB80Ss",
        "outputId": "f809f1ac-3fe3-4969-8c92-87a1286270ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            sentence\n",
            "0  laws relating to mines & minerals in indiathe ...\n",
            "1  and, in general, the most precise way of demar...\n",
            "2  there are many reasons for this; but one of th...\n",
            "3  however, the most important of those provision...\n",
            "4  from the point of view of the subject matter o...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your data is in a file named 'chatbot_data.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "  data = file.read()\n",
        "\n",
        "# Preprocessing (optional)\n",
        "cleaned_data = re.sub(r'\\n', '', data)  # Remove newline characters\n",
        "sentences = cleaned_data.split(\". \")  # Split by full stop followed by space\n",
        "sentences = [sentence for sentence in sentences if sentence.strip()]  # Remove empty elements\n",
        "\n",
        "# Optional further processing (lowercasing, stopword removal)\n",
        "sentences = [sentence.lower() for sentence in sentences]\n",
        "\n",
        "# Create a DataFrame (optional)\n",
        "df = pd.DataFrame(sentences, columns=['sentence'])\n",
        "\n",
        "# Print or use the preprocessed data (sentences or DataFrame)\n",
        "print(df.head())  # Print the first few sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRTIi6mD9jBW",
        "outputId": "7f0bbdb8-57d6-4e86-ed44-ad67a20b3554"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqm--4O7-Z0d",
        "outputId": "16bd6168-015e-4f6b-bc05-07b13ea59ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC854npw-hLq",
        "outputId": "3f7a9482-22a7-4adb-f629-5cfe63c0e9f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%pip` not found (But line magic `%pip` exists, did you mean that instead?).\n"
          ]
        }
      ],
      "source": [
        "%%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ5iiiPK-coc"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhHT667u9dSK",
        "outputId": "3fbcfab9-32c2-456d-d271-3f6566e0acdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted intent for 'What are the regulations for obtaining a mining lease in India?': central_government_role\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# Assuming you have your preprocessed sentences in a list named 'sentences'\n",
        "\n",
        "# Define some example intents and their corresponding keywords\n",
        "intents = [\n",
        "  {'intent': 'regulations_lease', 'keywords': ['regulations', 'lease', 'mining']},\n",
        "  {'intent': 'minerals_india', 'keywords': ['minerals', 'india']},\n",
        "  {'intent': 'central_government_role', 'keywords': ['central government', 'role', 'mining']},\n",
        "  # Add more intents and keywords as needed\n",
        "]\n",
        "\n",
        "# Feature Extraction function (using word presence as features)\n",
        "def extract_features(sentence):\n",
        "  words = word_tokenize(sentence.lower())  # Tokenize and lowercase the sentence\n",
        "  features = {}\n",
        "  for intent in intents:\n",
        "    for keyword in intent['keywords']:\n",
        "      features[f'contains_{keyword}'] = (keyword in words)  # Check if keyword is present\n",
        "  return features\n",
        "\n",
        "# Training data preparation\n",
        "training_data = [(extract_features(sentence), intent['intent']) for sentence, intent in zip(sentences, intents)]\n",
        "\n",
        "# Train the Naive Bayes Classifier model\n",
        "classifier = NaiveBayesClassifier.train(training_data)\n",
        "\n",
        "# Train the model\n",
        "model = NaiveBayesClassifier.train(training_data)\n",
        "\n",
        "# Example usage: Classify a new user query\n",
        "new_query = \"What are the regulations for obtaining a mining lease in India?\"\n",
        "predicted_intent = classifier.classify(extract_features(new_query))\n",
        "print(f\"Predicted intent for '{new_query}': {predicted_intent}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iVhLR3DBJ1X"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1sfcnNKBYJs"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np8SJl7GBim8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('words')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb06iF7i_nyO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "# Assuming you have your preprocessed sentences in a list named 'sentences'\n",
        "\n",
        "# Define some example intents and their corresponding keywords\n",
        "intents = [\n",
        "    {'intent': 'regulations_lease', 'keywords': ['regulations', 'lease', 'mining']},\n",
        "    {'intent': 'minerals_india', 'keywords': ['minerals', 'india']},\n",
        "    {'intent': 'central_government_role', 'keywords': ['central government', 'role', 'mining']},\n",
        "    # Add more intents and keywords as needed\n",
        "]\n",
        "\n",
        "# Feature Extraction function (using word presence as features)\n",
        "def extract_features(sentence):\n",
        "    words = word_tokenize(sentence.lower())  # Tokenize and lowercase the sentence\n",
        "    features = {}\n",
        "    for intent in intents:\n",
        "        for keyword in intent['keywords']:\n",
        "            features[f'contains_{keyword}'] = (keyword in words)  # Check if keyword is present\n",
        "    return features\n",
        "\n",
        "# Training data preparation\n",
        "training_data = [(extract_features(sentence), intent['intent']) for sentence, intent in zip(sentences, intents)]\n",
        "\n",
        "# Train the Naive Bayes Classifier model\n",
        "classifier = NaiveBayesClassifier.train(training_data)\n",
        "\n",
        "# Define some entity types and regular expressions for matching (English)\n",
        "entity_types = [\n",
        "    ('MINERAL', r'(?i)\\b(gold|silver|copper|iron|lead|zinc|coal|oil|gas|petroleum|natural gas)\\b'),\n",
        "    ('LOCATION', r'(?i)\\b(india|state|province|district)\\b'),  # Focus on locations relevant to Indian mining laws\n",
        "    ('ORGANIZATION', r'(?i)\\b(ministry of mines|indian bureau of mines|state mining department)\\b'),  # Relevant organizations\n",
        "    ('REGULATION', r'(?i)\\b(mmdr act|mineral concession rules|mines act|environment clearance|forest clearance)\\b'),  # Regulations related to Indian mining\n",
        "    # Add more entity types and regular expressions as needed\n",
        "]\n",
        "\n",
        "\n",
        "def extract_entities(sentence, classifier, intents):\n",
        "    \"\"\"\n",
        "    This function takes a sentence, the trained classifier model, and the intents list\n",
        "    and returns a dictionary containing the predicted intent and extracted entities.\n",
        "    \"\"\"\n",
        "def extract_entities(sentence, classifier, intents):\n",
        "    \"\"\"\n",
        "    This function takes a sentence, the trained classifier model, and the intents list\n",
        "    and returns a dictionary containing the predicted intent and extracted entities.\n",
        "    \"\"\"\n",
        "    # Classify the sentence using the trained model\n",
        "    predicted_intent = classifier.classify(extract_features(sentence))\n",
        "\n",
        "    # Ensure tokens are a list of strings (fix for the error)\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    # Find named entity chunks using regular expressions\n",
        "    tagged_tokens = [pos_tag(token) for token in tokens]  # Part-of-speech tagging\n",
        "    chunked_tokens = conlltags(tagged_tokens, entity_types)\n",
        "\n",
        "    # Extract entities based on intent and chunk tags\n",
        "    entities = {}\n",
        "    for chunk in chunked_tokens:  # Add the missing colon here\n",
        "        if chunk[0] in [t[0] for t in intents[predicted_intent]['keywords']]:  # Check if entity type matches intent keywords\n",
        "            entity_type, entity_text = chunk\n",
        "            entities[entity_type] = entities.get(entity_type, []) + [entity_text]  # Add entity to the dictionary\n",
        "\n",
        "    return {'intent': predicted_intent, 'entities': entities}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxiTZu7__4Zt"
      },
      "outputs": [],
      "source": [
        "!pip install rasa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_m3WNJjkAW5"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8nPJL6JkBd3"
      },
      "outputs": [],
      "source": [
        "!rasa init --no-prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa0NINyIkEWu"
      },
      "outputs": [],
      "source": [
        "!rasa train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLhwezBSkHi3"
      },
      "outputs": [],
      "source": [
        "!rasa run --enable-api --cors \"*\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlfs7f_qkKrG"
      },
      "outputs": [],
      "source": [
        "!pip install rasa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MPtnN7TkX-2",
        "outputId": "575325c0-f7c4-4716-8294-e867662fbe7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/core/tracker_store.py:1044: MovedIn20Warning: \u001b[31mDeprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. \u001b[32mTo prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". \u001b[36mSet environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message.\u001b[0m (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "\u001b(0lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\u001b(B\n",
            "\u001b(0x\u001b(B Rasa Open Source reports anonymous usage telemetry to help improve the product \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B for all its users.                                                             \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B                                                                                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B If you'd like to opt-out, you can use `rasa telemetry disable`.                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B To learn more, check out https://rasa.com/docs/rasa/telemetry/telemetry.       \u001b(0x\u001b(B\n",
            "\u001b(0mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u001b(B\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "\u001b[92mWelcome to Rasa! 🤖\n",
            "\u001b[0m\n",
            "To get started quickly, an initial project will be created.\n",
            "If you need some help, check out the documentation at https://rasa.com/docs/rasa.\n",
            "\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/config.yml -> .\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - creating data\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/data/rules.yml -> ./data\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/data/stories.yml -> ./data\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/data/nlu.yml -> ./data\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - creating tests\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/tests/test_stories.yml -> ./tests\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/endpoints.yml -> .\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - creating actions\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - creating actions/__pycache__\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/actions/__pycache__/__init__.cpython-310.pyc -> ./actions/__pycache__\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/actions/__pycache__/actions.cpython-310.pyc -> ./actions/__pycache__\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/actions/__init__.py -> ./actions\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/actions/actions.py -> ./actions\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/credentials.yml -> .\n",
            "2024-03-21 15:17:43 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - copying /usr/local/lib/python3.10/dist-packages/rasa/cli/initial_project/domain.yml -> .\n",
            "Created project directory at '/content'.\n",
            "\u001b[92mFinished creating project structure.\u001b[0m\n",
            "\u001b[92mTraining an initial model...\u001b[0m\n",
            "2024-03-21 15:17:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mnumexpr.utils\u001b[0m  - NumExpr defaulting to 2 threads.\n",
            "\u001b[94mThe configuration for policies and pipeline was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'RegexFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'RegexFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'LexicalSyntacticFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'LexicalSyntacticFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'CountVectorsFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer\u001b[0m  - 80 vocabulary items were created for text attribute.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'CountVectorsFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'CountVectorsFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer\u001b[0m  - 697 vocabulary items were created for text attribute.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'CountVectorsFeaturizer'.\n",
            "2024-03-21 15:17:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'DIETClassifier'.\n",
            "Epochs: 100% 100/100 [00:44<00:00,  2.25it/s, t_loss=1.14, i_acc=1]\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'DIETClassifier'.\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'EntitySynonymMapper'.\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'EntitySynonymMapper'.\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'ResponseSelector'.\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.nlu.selectors.response_selector\u001b[0m  - Retrieval intent parameter was left to its default value. This response selector will be trained on training examples combining all retrieval intents.\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'ResponseSelector'.\n",
            "Processed story blocks: 100% 3/3 [00:00<00:00, 2382.68it/s, # trackers=1]\n",
            "Processed story blocks: 100% 3/3 [00:00<00:00, 1083.24it/s, # trackers=3]\n",
            "Processed story blocks: 100% 3/3 [00:00<00:00, 268.68it/s, # trackers=12]\n",
            "Processed story blocks: 100% 3/3 [00:00<00:00, 71.06it/s, # trackers=39]\n",
            "Processed rules: 100% 2/2 [00:00<00:00, 2623.08it/s, # trackers=1]\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'MemoizationPolicy'.\n",
            "Processed trackers: 100% 3/3 [00:00<00:00, 1801.68it/s, # action=12]\n",
            "Processed actions: 12it [00:00, 7259.72it/s, # examples=12]\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'MemoizationPolicy'.\n",
            "2024-03-21 15:18:34 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'RulePolicy'.\n",
            "Processed trackers: 100% 2/2 [00:00<00:00, 1638.40it/s, # action=5]\n",
            "Processed actions: 5it [00:00, 11997.44it/s, # examples=4]\n",
            "Processed trackers: 100% 3/3 [00:00<00:00, 2044.01it/s, # action=12]\n",
            "Processed trackers: 100% 2/2 [00:00<00:00, 1658.48it/s]\n",
            "Processed trackers: 100% 5/5 [00:00<00:00, 1392.16it/s]\n",
            "2024-03-21 15:18:35 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'RulePolicy'.\n",
            "2024-03-21 15:18:35 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'TEDPolicy'.\n",
            "Processed trackers: 100% 120/120 [00:00<00:00, 2290.02it/s, # action=30]\n",
            "Epochs: 100% 100/100 [00:21<00:00,  4.57it/s, t_loss=1.32, loss=1.15, acc=1]\n",
            "2024-03-21 15:18:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'TEDPolicy'.\n",
            "2024-03-21 15:18:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Starting to train component 'UnexpecTEDIntentPolicy'.\n",
            "2024-03-21 15:18:59 \u001b[1;30mWARNING \u001b[0m \u001b[34mrasa.shared.utils.common\u001b[0m  - \u001b[33mThe UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\u001b[0m\n",
            "Processed trackers: 100% 120/120 [00:00<00:00, 3638.94it/s, # intent=12]\n",
            "Epochs: 100% 100/100 [00:19<00:00,  5.10it/s, t_loss=0.124, loss=0.00881, acc=1]\n",
            "2024-03-21 15:19:27 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Finished training component 'UnexpecTEDIntentPolicy'.\n",
            "\u001b[92mYour Rasa model is trained and saved at 'models/20240321-151748-oriented-formant.tar.gz'.\u001b[0m\n",
            "If you want to speak to the assistant, run 'rasa shell' at any time inside the project directory.\n"
          ]
        }
      ],
      "source": [
        "!rasa init --no-prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58SfyRJPltSX",
        "outputId": "e726bb3d-7482-48f4-e0ed-cb7b7fae774e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/core/tracker_store.py:1044: MovedIn20Warning: \u001b[31mDeprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. \u001b[32mTo prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". \u001b[36mSet environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message.\u001b[0m (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "2024-03-21 15:19:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.cli.train\u001b[0m  - Started validating domain and training data...\n",
            "2024-03-21 15:19:56 \u001b[1;30mINFO    \u001b[0m \u001b[34mnumexpr.utils\u001b[0m  - NumExpr defaulting to 2 threads.\n",
            "2024-03-21 15:19:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Validating intents...\n",
            "2024-03-21 15:19:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Validating uniqueness of intents and stories...\n",
            "2024-03-21 15:19:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Validating utterances...\n",
            "2024-03-21 15:19:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - Story structure validation...\n",
            "Processed story blocks: 100% 3/3 [00:00<00:00, 1611.13it/s, # trackers=1]\n",
            "2024-03-21 15:19:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.training.story_conflict\u001b[0m  - Considering all preceding turns for conflict analysis.\n",
            "2024-03-21 15:19:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.validator\u001b[0m  - No story structure conflicts found.\n",
            "\u001b[94mThe configuration for policies and pipeline was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'CountVectorsFeaturizer' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'CountVectorsFeaturizer' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'DIETClassifier' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'EntitySynonymMapper' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'LexicalSyntacticFeaturizer' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'MemoizationPolicy' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'RegexFeaturizer' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'ResponseSelector' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'RulePolicy' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'TEDPolicy' from cache.\n",
            "2024-03-21 15:19:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.engine.training.hooks\u001b[0m  - Restored component 'UnexpecTEDIntentPolicy' from cache.\n",
            "\u001b[92mYour Rasa model is trained and saved at 'models/20240321-151959-rapid-sport.tar.gz'.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!rasa train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rejl5oHbmNCv",
        "outputId": "69a64abd-0a9e-4faf-ef2e-0b168aaa405f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/core/tracker_store.py:1044: MovedIn20Warning: \u001b[31mDeprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. \u001b[32mTo prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". \u001b[36mSet environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message.\u001b[0m (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/sanic_cors/extension.py:39: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  SANIC_VERSION = LooseVersion(sanic_version)\n",
            "2024-03-21 15:31:04 \u001b[1;30mINFO    \u001b[0m \u001b[34mnumexpr.utils\u001b[0m  - NumExpr defaulting to 2 threads.\n",
            "2024-03-21 15:31:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Starting Rasa server on http://0.0.0.0:5005\n",
            "2024-03-21 15:31:06 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa.core.processor\u001b[0m  - Loading model models/20240321-151959-rapid-sport.tar.gz...\n",
            "2024-03-21 15:31:38 \u001b[1;30mWARNING \u001b[0m \u001b[34mrasa.shared.utils.common\u001b[0m  - \u001b[33mThe UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\u001b[0m\n",
            "2024-03-21 15:31:54 \u001b[1;30mINFO    \u001b[0m \u001b[34mroot\u001b[0m  - Rasa server is up and running.\n"
          ]
        }
      ],
      "source": [
        "!rasa run --enable-api --cors \"*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iN2otoEmSC2"
      },
      "outputs": [],
      "source": [
        "# Assuming your model object is named 'model' and it's trained already\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'classifier.pkl')\n",
        "joblib.dump(model, 'vectorize.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
